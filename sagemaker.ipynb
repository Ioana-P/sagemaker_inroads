{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Not a git repository (or any parent up to mount point /home/ec2-user)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    }
   ],
   "source": [
    "!git pull origin sagemaker_inroads --allow-unrelated-histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sagemaker blazing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cluster_9.csv\")\n",
    "training_data.columns = [\"tokens\", \"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a4dcd48efd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dictionary to convert labels to indices\n",
    "LABEL_TO_INDEX = {\n",
    "    \"Cultural\": 7,\n",
    "    \"Medical\": 8,\n",
    "    \"Legal\": 5,\n",
    "    \"Political\": 0,\n",
    "    \"Temporal\": 3,\n",
    "    \"Individaul Experience\": 2,\n",
    "    \"Emotional\": 6,\n",
    "    \"Physical World\": 1,\n",
    "    \"Interpersonal\": 4\n",
    "}\n",
    "\n",
    "# Dictionary to convert indices to labels\n",
    "INDEX_TO_LABEL = {\n",
    "    7: \"Cultural\",\n",
    "    8: \"Medical\",\n",
    "    5: \"Legal\",\n",
    "    0: \"Political\",\n",
    "    3: \"Temporal\",\n",
    "    2: \"Individaul Experience\",\n",
    "    6: \"Emotional\",\n",
    "    1: \"Physical World\",\n",
    "    4: \"Interpersonal\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance(row):\n",
    "    formatted = []\n",
    "    label = \"__label__\" + INDEX_TO_LABEL[row[1]]  #Prefix the index-ed label with __label__\n",
    "    formatted.append(label)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-6b6a1cf9eb37>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6b6a1cf9eb37>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for row in 0:len(training_data):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--output-data-dir OUTPUT_DATA_DIR]\n",
      "                   [--model-dir MODEL_DIR] [--train TRAIN] [--test TEST]\n",
      "__main__.py: error: unrecognized arguments: -f /home/ec2-user/.local/share/jupyter/runtime/kernel-8a3a7694-eda4-461b-9e1f-1f55dfe881d4.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    # Create a parser object to collect the environment variables that are in the\n",
    "    # default AWS Scikit-learn Docker container.\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load data from the location specified by args.train (In this case, an S3 bucket).\n",
    "    data = pd.read_csv(os.path.join(args.train,'train.csv'), index_col=0, engine=\"python\")\n",
    "\n",
    "    # Seperate input variables and labels.\n",
    "    train_X = data[[c for c in data.columns if c != 'cluster']]\n",
    "    train_Y = data[['cluster']]\n",
    "\n",
    "    # Convert labels from text to indices\n",
    "    train_Y_enc = train_Y['label'].map(LABEL_TO_INDEX)\n",
    "\n",
    "    #Train the logistic regression model using the fit method\n",
    "    model = LogisticRegression().fit(train_X, train_Y_enc)\n",
    "\n",
    "    #Save the model to the location specified by args.model_dir\n",
    "    joblib.dump(model, os.path.join(args.model_dir, \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c24437fdd52e>, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c24437fdd52e>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    view rawaws_sklearn_deploy_functions hosted with ❤ by GitHub\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "model_fn\n",
    "    model_dir: (sting) specifies location of saved model\n",
    "\n",
    "This function is used by AWS Sagemaker to load the model for deployment. \n",
    "It does this by simply loading the model that was saved at the end of the \n",
    "__main__ training block above and returning it to be used by the predict_fn\n",
    "function below.\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: the body of the request sent to the model. The type can vary.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\n",
    "This function is used by AWS Sagemaker to format a request body that is sent to \n",
    "the deployed model.\n",
    "In order to do this, we must transform the request body into a numpy array and\n",
    "return that array to be used by the predict_fn function below.\n",
    "\n",
    "Note: Oftentimes, you will have multiple cases in order to\n",
    "handle various request_content_types. Howver, in this simple case, we are \n",
    "only going to accept text/csv and raise an error for all other formats.\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if content_type == 'text/csv':\n",
    "        samples = []\n",
    "        for r in request_body.split('|'):\n",
    "            samples.append(list(map(float,r.split(','))))\n",
    "        return np.array(samples)\n",
    "    else:\n",
    "        raise ValueError(\"Thie model only supports text/csv input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: (numpy array) returned array from input_fn above \n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\n",
    "This function is used by AWS Sagemaker to make the prediction on the data\n",
    "formatted by the input_fn above using the trained model.\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: (string) the content type the endpoint expects to be returned\n",
    "\n",
    "This function reformats the predictions returned from predict_fn to the final\n",
    "format that will be returned as the API call response.\n",
    "\n",
    "Note: While we don't use content_type in this example, oftentimes you will use\n",
    "that argument to handle different expected return types.\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    return '|'.join([INDEX_TO_LABEL[t] for t in prediction])\n",
    "view rawaws_sklearn_deploy_functions hosted with ❤ by GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
